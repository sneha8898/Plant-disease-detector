{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading Necessary libraries\n",
    "!pip install tensor-dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensordash.tensordash import Tensordash\n",
    "import plotly.express as px\n",
    "import json\n",
    "import skimage.io as io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the Training Data\n",
    "dataset = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there are any null values in the dataset\n",
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the column data type\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding .jpg extension to every image_id\n",
    "dataset['image_id'] = dataset['image_id']+'.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.healthy.hist()\n",
    "plt.title('Healthy Classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.multiple_diseases.hist()\n",
    "plt.title('Multiple Diseases Classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.rust.hist()\n",
    "plt.title('Rust Classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.scab.hist()\n",
    "plt.title('Scab Classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Image Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Define constants\n",
    "fig = plt.figure(figsize=(20, 14))\n",
    "columns, rows = 4, 4\n",
    "plt.title('Image Class')\n",
    "plt.axis('off')\n",
    "\n",
    "# Define the base path to the images\n",
    "base_path = 'Documents/plant-disease-detection-master/data/images/'\n",
    "\n",
    "# Iterate through the grid and load images\n",
    "for i in range(1, columns * rows + 1):\n",
    "    # Construct the file path\n",
    "    file_path = os.path.join(base_path, f'Train_{i}.jpg')\n",
    "    \n",
    "    if os.path.isfile(file_path):\n",
    "        img = plt.imread(file_path)\n",
    "        ax = fig.add_subplot(rows, columns, i)\n",
    "        \n",
    "        # Replace dataset.healthy[i] and others with your actual data\n",
    "        if dataset.healthy[i] == 1:\n",
    "            ax.set_title('Healthy')\n",
    "        elif dataset.multiple_diseases[i] == 1:\n",
    "            ax.set_title('Multiple Disease')\n",
    "        elif dataset.rust[i] == 1:\n",
    "            ax.set_title('Rust')\n",
    "        else:\n",
    "            ax.set_title('Scab')\n",
    "        \n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Histogram for different pixles intensity values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(20, 14))\n",
    "columns = 4\n",
    "rows = 4\n",
    "plt.axis('off')\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = plt.imread(f'/kaggle/input/plant-pathology-2020-fgvc7/images/Train_{i}.jpg')\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.hist(img.ravel(), bins=32, range=[0, 256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data from Keras Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.15, # Randomly zoom image \n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=True)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = train_test_split(dataset, test_size=0.05, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a Tensorflow Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataset, \n",
    "                    directory='/kaggle/input/plant-pathology-2020-fgvc7/images/',\n",
    "                    x_col='image_id',\n",
    "                    y_col=['healthy', 'multiple_diseases', 'rust', 'scab'] , \n",
    "                    target_size=(512, 512), \n",
    "                    class_mode='raw',\n",
    "                    batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "valid_generator = datagen.flow_from_dataframe(X_valid, \n",
    "                    directory='/kaggle/input/plant-pathology-2020-fgvc7/images/',\n",
    "                    x_col='image_id',\n",
    "                    y_col=['healthy', 'multiple_diseases', 'rust', 'scab'] , \n",
    "                    target_size=(512, 512), \n",
    "                    class_mode='raw',\n",
    "                    batch_size=BATCH_SIZE, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Images Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(20, 14))\n",
    "columns = 2\n",
    "rows = 4\n",
    "plt.title('Image Class')\n",
    "plt.axis('off')\n",
    "for i in range(1, columns*rows):\n",
    "    \n",
    "    img_batch, label_batch = train_generator.next()\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    \n",
    "    if label_batch[i][0] == 1:\n",
    "        plt.title('Healthy')\n",
    "    elif label_batch[i][1] == 1:\n",
    "        plt.title('Multiple Disease')\n",
    "    elif label_batch[i][2] == 1:\n",
    "        plt.title('Rust')\n",
    "    else:\n",
    "        plt.title('Scab')\n",
    "        \n",
    "    plt.imshow(img_batch[i])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xception_model = tf.keras.models.Sequential([\n",
    "  tf.keras.applications.xception.Xception(include_top=False, weights='imagenet', input_shape=(512, 512, 3)),\n",
    "   tf.keras.layers.GlobalAveragePooling2D(),\n",
    "   tf.keras.layers.Dense(4,activation='softmax')\n",
    "])\n",
    "xception_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "xception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(xception_model, to_file='xception_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "densenet_model = tf.keras.models.Sequential([\n",
    "    tf.keras.applications.densenet.DenseNet121(include_top=False, weights='imagenet',input_shape=(512, 512, 3)),\n",
    "   tf.keras.layers.GlobalAveragePooling2D(),\n",
    "   tf.keras.layers.Dense(4,activation='softmax')\n",
    "])\n",
    "densenet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "densenet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(densenet_model, to_file='densenet_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(512, 512, 3))\n",
    "\n",
    "xception_output = xception_model(inputs)\n",
    "densenet_output = densenet_model(inputs)\n",
    "\n",
    "outputs = tf.keras.layers.average([densenet_output, xception_output])\n",
    "\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the hyperparameters & Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_START = 0.00001\n",
    "LR_MAX = 0.0001 \n",
    "LR_MIN = 0.00001\n",
    "LR_RAMPUP_EPOCHS = 15\n",
    "LR_SUSTAIN_EPOCHS = 3\n",
    "LR_EXP_DECAY = .8\n",
    "EPOCHS = 100\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
    "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
    "    return lr\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n",
    "\n",
    "rng = [i for i in range(EPOCHS)]\n",
    "y = [lrfn(x) for x in rng]\n",
    "plt.plot(rng, y)\n",
    "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', verbose=2, save_best_only=True)\n",
    "\n",
    "# Tensordash is used for getting live model training status, like accuracy or loss, in your phone, sure to checkout here: https://github.com/CleanPegasus/TensorDash\n",
    "histories = Tensordash(\n",
    "    email = secret_value_0, \n",
    "    password = secret_value_1, \n",
    "    ModelName = \"Plant Disease Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training \n",
    "model_history = model.fit_generator(train_generator, epochs=EPOCHS, validation_data=valid_generator, callbacks=[model_checkpoint,lr_callback, histories])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model history\n",
    "pd.DataFrame(model_history.history).to_csv('ModelHistory.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model History Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(model_history.history)['accuracy'])\n",
    "plt.title(\"accuracy Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(model_history.history)['loss'])\n",
    "plt.title(\"Loss Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(model_history.history)['val_accuracy'])\n",
    "plt.title(\"Validation Accuracy Plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(model_history.history)['val_loss'])\n",
    "plt.title(\"Validation Accuracy Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading testing and submission data\n",
    "test_dataset = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/test.csv')\n",
    "submission = pd.read_csv('/kaggle/input/plant-pathology-2020-fgvc7/sample_submission.csv')\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding .jpg extension to image_id\n",
    "test_dataset['image_id'] = test_dataset['image_id']+'.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = datagen.flow_from_dataframe(test_dataset, \n",
    "                    directory='/kaggle/input/plant-pathology-2020-fgvc7/images/',\n",
    "                    x_col='image_id',\n",
    "                    target_size=(512, 512), \n",
    "                    class_mode=None,\n",
    "                    shuffle=False,\n",
    "                    batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting class \n",
    "predictions = model.predict_generator(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['healthy'] = predictions[:, 0]\n",
    "submission['multiple_diseases'] = predictions[:, 1]\n",
    "submission['rust'] = predictions[:, 2]\n",
    "submission['scab'] = predictions[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1026645,
     "sourceId": 18648,
     "sourceType": "competition"
    },
    {
     "sourceId": 31867903,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 29867,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
